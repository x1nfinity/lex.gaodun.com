/**
 * é€šç”¨AIæœåŠ¡
 * æ”¯æŒå¤šä¸ªAIæ¨¡å‹æä¾›å•†
 */

import { AIModelConfig } from '../config/prompts';

export interface AIResponse {
    content: string;
    usage?: {
        prompt_tokens: number;
        completion_tokens: number;
        total_tokens: number;
    };
}

export interface AIRequestOptions {
    model: AIModelConfig;
    prompt: string;
    apiKey: string;
    maxTokens?: number;
    temperature?: number;
}

/**
 * DeepSeek APIè°ƒç”¨
 */
async function callDeepSeekAPI(options: AIRequestOptions): Promise<AIResponse> {
    const { model, prompt, apiKey, maxTokens, temperature } = options;

    console.log('ğŸ¤– è°ƒç”¨DeepSeek API:', {
        url: model.apiUrl,
        prompt: prompt.substring(0, 100) + '...',
        maxTokens,
        temperature,
    });

    const response = await fetch(model.apiUrl, {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            Authorization: `Bearer ${apiKey}`,
            ...model.headers,
        },
        body: JSON.stringify({
            model: 'deepseek-chat',
            messages: [
                {
                    role: 'user',
                    content: prompt,
                },
            ],
            max_tokens: maxTokens || model.maxTokens || 1000,
            temperature: temperature || model.temperature || 0.7,
        }),
    });

    if (!response.ok) {
        const errorData = await response.text();
        console.error('âŒ DeepSeek APIé”™è¯¯:', {
            status: response.status,
            statusText: response.statusText,
            error: errorData,
        });
        throw new Error(`DeepSeek APIè°ƒç”¨å¤±è´¥: ${response.status} ${response.statusText}`);
    }

    const data = await response.json();
    console.log('âœ… DeepSeek APIå“åº”:', {
        content: data.choices?.[0]?.message?.content?.substring(0, 100) + '...',
        usage: data.usage,
    });

    return {
        content: data.choices?.[0]?.message?.content || '',
        usage: data.usage,
    };
}

/**
 * è±†åŒ…(Doubao) APIè°ƒç”¨
 */
async function callDoubaoAPI(options: AIRequestOptions): Promise<AIResponse> {
    const { model, prompt, apiKey, maxTokens, temperature } = options;

    console.log('ğŸ¤– è°ƒç”¨è±†åŒ…API:', {
        url: model.apiUrl,
        prompt: prompt.substring(0, 100) + '...',
        maxTokens,
        temperature,
    });

    const response = await fetch(model.apiUrl, {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            Authorization: `Bearer ${apiKey}`,
            ...model.headers,
        },
        body: JSON.stringify({
            model: 'ep-20251015101857-wc8xz', // è±†åŒ…æ¨¡å‹IDï¼Œå¯é…ç½®
            messages: [
                {
                    role: 'user',
                    content: prompt,
                },
            ],
            max_tokens: maxTokens || model.maxTokens || 1000,
            temperature: temperature || model.temperature || 0.7,
        }),
    });

    if (!response.ok) {
        const errorData = await response.text();
        console.error('âŒ è±†åŒ…APIé”™è¯¯:', {
            status: response.status,
            statusText: response.statusText,
            error: errorData,
        });
        throw new Error(`è±†åŒ…APIè°ƒç”¨å¤±è´¥: ${response.status} ${response.statusText}`);
    }

    const data = await response.json();
    console.log('âœ… è±†åŒ…APIå“åº”:', {
        content: data.choices?.[0]?.message?.content?.substring(0, 100) + '...',
        usage: data.usage,
    });

    return {
        content: data.choices?.[0]?.message?.content || '',
        usage: data.usage,
    };
}

/**
 * é€šä¹‰åƒé—® APIè°ƒç”¨
 */
async function callQwenAPI(options: AIRequestOptions): Promise<AIResponse> {
    const { model, prompt, apiKey, maxTokens, temperature } = options;

    console.log('ğŸ¤– è°ƒç”¨é€šä¹‰åƒé—®API:', {
        url: model.apiUrl,
        prompt: prompt.substring(0, 100) + '...',
        maxTokens,
        temperature,
    });

    const response = await fetch(model.apiUrl, {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            Authorization: `Bearer ${apiKey}`,
            'X-DashScope-SSE': 'disable',
            ...model.headers,
        },
        body: JSON.stringify({
            model: 'qwen-turbo',
            input: {
                messages: [
                    {
                        role: 'user',
                        content: prompt,
                    },
                ],
            },
            parameters: {
                max_tokens: maxTokens || model.maxTokens || 1000,
                temperature: temperature || model.temperature || 0.7,
            },
        }),
    });

    if (!response.ok) {
        const errorData = await response.text();
        console.error('âŒ é€šä¹‰åƒé—®APIé”™è¯¯:', {
            status: response.status,
            statusText: response.statusText,
            error: errorData,
        });
        throw new Error(`é€šä¹‰åƒé—®APIè°ƒç”¨å¤±è´¥: ${response.status} ${response.statusText}`);
    }

    const data = await response.json();
    console.log('âœ… é€šä¹‰åƒé—®APIå“åº”:', {
        content: data.output?.text?.substring(0, 100) + '...',
        usage: data.usage,
    });

    return {
        content: data.output?.text || '',
        usage: data.usage,
    };
}

/**
 * ChatGPT APIè°ƒç”¨
 */
async function callChatGPTAPI(options: AIRequestOptions): Promise<AIResponse> {
    const { model, prompt, apiKey, maxTokens, temperature } = options;

    console.log('ğŸ¤– è°ƒç”¨ChatGPT API:', {
        url: model.apiUrl,
        prompt: prompt.substring(0, 100) + '...',
        maxTokens,
        temperature,
    });

    const response = await fetch(model.apiUrl, {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            Authorization: `Bearer ${apiKey}`,
            ...model.headers,
        },
        body: JSON.stringify({
            model: 'gpt-3.5-turbo',
            messages: [
                {
                    role: 'user',
                    content: prompt,
                },
            ],
            max_tokens: maxTokens || model.maxTokens || 1000,
            temperature: temperature || model.temperature || 0.7,
        }),
    });

    if (!response.ok) {
        const errorData = await response.text();
        console.error('âŒ ChatGPT APIé”™è¯¯:', {
            status: response.status,
            statusText: response.statusText,
            error: errorData,
        });
        throw new Error(`ChatGPT APIè°ƒç”¨å¤±è´¥: ${response.status} ${response.statusText}`);
    }

    const data = await response.json();
    console.log('âœ… ChatGPT APIå“åº”:', {
        content: data.choices?.[0]?.message?.content?.substring(0, 100) + '...',
        usage: data.usage,
    });

    return {
        content: data.choices?.[0]?.message?.content || '',
        usage: data.usage,
    };
}

/**
 * é€šç”¨AIæœåŠ¡è°ƒç”¨
 */
export async function callAIService(options: AIRequestOptions): Promise<AIResponse> {
    const { model } = options;

    try {
        switch (model.provider) {
            case 'deepseek':
                return await callDeepSeekAPI(options);
            case 'doubao':
                return await callDoubaoAPI(options);
            case 'qwen':
                return await callQwenAPI(options);
            case 'openai':
                return await callChatGPTAPI(options);
            default:
                throw new Error(`ä¸æ”¯æŒçš„AIæ¨¡å‹æä¾›å•†: ${model.provider}`);
        }
    } catch (error) {
        console.error('âŒ AIæœåŠ¡è°ƒç”¨å¤±è´¥:', error);
        throw error;
    }
}

/**
 * ç”Ÿæˆè§†é¢‘è„šæœ¬
 */
export async function generateVideoScript(prompt: string, model: AIModelConfig, apiKey: string): Promise<string> {
    const response = await callAIService({
        model,
        prompt,
        apiKey,
    });

    return response.content;
}
